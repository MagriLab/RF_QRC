{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Dynamical Systems using Reservoir Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from QRC.solvers import *\n",
    "from QRC.systems import *\n",
    "from QRC.post_process import *\n",
    "from QRC.crc import *\n",
    "from QRC.qrc import *\n",
    "from QRC.validation import *\n",
    "\n",
    "import h5py\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import eigs as sparse_eigs\n",
    "import skopt\n",
    "\n",
    "\n",
    "#plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex = True)\n",
    "mpl.rc('font', family = 'serif')\n",
    "mpl.rcParams['text.usetex']\n",
    "\n",
    "#scipy libraries\n",
    "from skopt.space import Real\n",
    "from skopt.learning import GaussianProcessRegressor as GPR\n",
    "from skopt.learning.gaussian_process.kernels import Matern, WhiteKernel, Product, ConstantKernel\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "from skopt.plots import plot_convergence\n",
    "import scipy.stats as stats \n",
    "\n",
    "#QISKIT\n",
    "from qiskit import  QuantumCircuit, assemble, QuantumRegister, ClassicalRegister, transpile\n",
    "import random as rnd\n",
    "import time\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "#TODO\n",
    "# Add config file so that to run on HPC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Systems and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Lorenz 63:\n",
    "if __name__ == \"__main__\":\n",
    "    dt = 0.01\n",
    "    tot_steps = 100000\n",
    "    upsample = 1\n",
    "    q0 =  np.array([7.432487609628195, 10.02071718705213, 29.62297428638419])\n",
    "    #q0 =  np.array([0, 1, 1])\n",
    "    N_transient = 2000\n",
    "\n",
    "\n",
    "save_fold = 'VPT_L63'\n",
    "system = Systems(dt,tot_steps,q0,upsample,N_transient)\n",
    "\n",
    "dim,N_lyap,N_t = system.set_param_lorenz63() # FOR MFE, N_t should be input so in set_param_MFE -- make it as input\n",
    "q = system.gen_data_lorenz63()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laminarized precentage 0.0 (relevant for MFE)\n",
      "Retaining  1 series for training and validation\n",
      "Additional  500 series for testing and statistical predictions\n",
      "UU Size = (1, 98000, 3)\n",
      "U Size = (98000, 3)\n",
      "N_lyap: 111\n",
      "N_train = 20 N_lyap  x  1 series\n",
      "N = 27 N_lyap , Total steps of training= 2997 , Out of =  98000\n",
      "The shape of q_tv is (1, 98000, 3) to train on 1 time series\n",
      "The shape of q_test is (0, 98000, 3) to test 500 time series, and for stats predictions (relevant for MFE)\n",
      "The shape of q is (1, 98000, 3) combining above\n",
      "The shape of U_test is (1, 22199, 3) combining above\n"
     ]
    }
   ],
   "source": [
    "data_inputs = True\n",
    "noise       = False # to add noise in flattened time series \n",
    "scaling     = True # to scale flattened time series \n",
    "\n",
    "if data_inputs:\n",
    "    N_ts        = 1 #only first N_ts used for training and validation\n",
    "    N_test_stat = 500 # Time series for testing after N_ts\n",
    "\n",
    "    N_washout  = 2*N_lyap #10 before for L96 10 D , 2 before for L63 / MFE  \n",
    "    N_val      = 5*N_lyap # 3 for L63 , # 5 for L96 , 2*N_lyap for MFE\n",
    "    N_train    = 20*N_lyap #200 before for L96 10D , 20 before for L63 / MFE  \n",
    "    N_test     = 200*N_lyap\n",
    " \n",
    "\n",
    "\n",
    "# All above in this block are Inputs\n",
    "q_unscaled = q\n",
    "UU = q # backup of complete time series\n",
    "print('Laminarized precentage', np.round(100-((q.shape[0])*100/N_t),2),'(relevant for MFE)')\n",
    "\n",
    "q = q[:N_ts+N_test_stat,:,:] # trimmed time series\n",
    "\n",
    "print('Retaining ',N_ts, 'series for training and validation')\n",
    "print('Additional ',N_test_stat, 'series for testing and statistical predictions')\n",
    "\n",
    "# Rescaling Input Time Series after flattening it (only retained series)\n",
    "q0 = q.shape[0] # Total time series, Train+Val+Test\n",
    "q1 = q.shape[1] # Length of each time series\n",
    "q_U = q.reshape(q0*q1, dim)\n",
    "\n",
    "if scaling:\n",
    "    q = sklearn.preprocessing.minmax_scale(q_U, feature_range=(0, 1), axis=0, copy=True) # rescaling flattened array\n",
    "    q  = q.reshape(q0,q1,dim) # making 3 dimensional again\n",
    "\n",
    "# from here q has scaled data\n",
    "q_tv = q[:N_ts,:,:]  # From q retaining training set (N_ts)\n",
    "q_test = q[N_ts:N_ts+N_test_stat,:,:]  #From q removing retaining test set(N_test_stat)\n",
    "\n",
    "# Training, Validation Parameters\n",
    "UU = q_tv # Training, validation set\n",
    "N0 = UU.shape[0] # Retained Time series for training\n",
    "N1 = UU.shape[1] # Length of each time series\n",
    "print('UU Size =',UU.shape) # 3 dim\n",
    "U = UU.reshape(N0*N1, dim) # Generating flattened time series for addition of noise and normalization\n",
    "print('U Size =',U.shape) # 2 dim \n",
    "\n",
    "if noise: # adding noise in training set\n",
    "    target_snr_db=40\n",
    "    seed=0\n",
    "    UU = add_noise(U,target_snr_db,seed,dim,N0,N1)\n",
    "\n",
    "#compute norm\n",
    "U_data = U[:N_washout+N_train+N_val]\n",
    "m = U_data.min(axis=0)\n",
    "M = U_data.max(axis=0)\n",
    "norm = M-m\n",
    "u_mean = U_data.mean(axis=0)\n",
    "\n",
    "# washout\n",
    "U_washout = UU[:,:N_washout]\n",
    "# training + validation\n",
    "U_tv  = UU[:,N_washout:N_washout+N_train+N_val-1]\n",
    "Y_tv  = UU[:,N_washout+1:N_washout+N_train+N_val]\n",
    "# Testing\n",
    "U_test  = UU[:,N_washout+N_train+N_val:N_washout+N_train+N_val+N_test-1]\n",
    "Y_test  = UU[:,N_washout+N_train+N_val+1:N_washout+N_train+N_val+N_test]\n",
    "\n",
    "print('N_lyap:', N_lyap)\n",
    "print('N_train =',int(N_train/N_lyap),'N_lyap',' x ',str(N_ts),'series')\n",
    "print('N =',int((N_washout+N_val+N_train)/N_lyap),'N_lyap',', Total steps of training=',int(N_washout+N_val+N_train),', Out of = ',N0*N1)\n",
    "print('The shape of q_tv is '+str(q_tv.shape)+ ' to train on ' +str(N_ts)+  ' time series')\n",
    "print('The shape of q_test is '+str(q_test.shape)+ ' to test ' +str(N_test_stat)+  ' time series, and for stats predictions (relevant for MFE)')\n",
    "print('The shape of q is '+str(q.shape)+ ' combining above')\n",
    "print('The shape of U_test is '+str(U_test.shape)+ ' combining above')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = 8000\n",
    "# l2= 5000\n",
    "# l3= 5000\n",
    "\n",
    "# plot_lorenz63_attractor(U,l1)\n",
    "# plot_lorenz63_time(U,N_lyap,l2,l3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Reservoir Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density(D) =  0.11\n",
      "Connectivity =  56.21\n"
     ]
    }
   ],
   "source": [
    "# Required Input Parameters\n",
    "bias_in   = np.array([np.mean(np.abs((U_data-u_mean)/norm))]) #input bias (average absolute value of the inputs)\n",
    "bias_out  = np.array([1.]) #output bias \n",
    "N_units   = 512 #neurons\n",
    "density = 0.11 # L63\n",
    "#density = 0.01 # L96\n",
    "#connectivity = 30\n",
    "\n",
    "# Predefining Hyperparameter to initiate a class\n",
    "tikh = np.array([1e-9])  # Tikhonov factor (optimize among the values in this list) #TODO\n",
    "sigma_in = 1 # input scaling\n",
    "rho = 1\n",
    "epsilon = 1\n",
    "\n",
    "# Random Weight Matrices Seed\n",
    "seed = 2\n",
    "\n",
    "sparseness = 1 - density\n",
    "connectivity = (1 -  sparseness)*(N_units-1)\n",
    "\n",
    "# sparseness = 1-((connectivity)/(N_units-1))\n",
    "# density    = 1-sparseness\n",
    "print('Density(D) = ',np.round(density,2))\n",
    "print('Connectivity = ', np.round(connectivity,2))\n",
    "\n",
    "esn = EchoStateNetwork(tikh,sigma_in,rho,epsilon,bias_in,bias_out,N_units,dim,density)\n",
    "esn.norm_u = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation (hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in        = 10               #Number of Initial random points\n",
    "n_tot       = 50               #Total number of function evaluations\n",
    "\n",
    "#range for hyperparameters \n",
    "spec_in     = np.log10(0.01)   \n",
    "spec_end    = np.log10(1.0)   \n",
    "epsilon_in  = 0.01\n",
    "epsilon_end = 1\n",
    "scaling_in  = 0.01\n",
    "scaling_end = 1\n",
    "#Number of Networks in the ensemble\n",
    "ensemble = 5      \n",
    "    \n",
    "search_space = [Real(spec_in, spec_end, name='spectral_radius'),\n",
    "            Real(epsilon_in, epsilon_end, name='epsilon'),\n",
    "            Real(scaling_in,scaling_end, name = 'input_scaling')]\n",
    "\n",
    "kernell = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-1, 3e0)) *\\\n",
    "            Matern(length_scale=[0.2,0.1,0.3], nu=2.5, length_scale_bounds=(5e-2, 1e1)) \n",
    "\n",
    "\n",
    "k= 0\n",
    "# Which validaton strategy (implemented in Val_Functions.ipynb)\n",
    "val      = RVC_Noise_upt\n",
    "N_fo     = max(50,2)            # number of validation intervals\n",
    "N_in     = N_washout                  # timesteps before the first validation interval (can't be 0 due to implementation)\n",
    "N_fw     = (N_train-N_val)//(N_fo-1) # how many steps forward the validation interval is shifted (in this way they are evenly spaced)\n",
    "\n",
    "#Quantities to be saved\n",
    "par      = np.zeros((ensemble, 5))      # GP parameters\n",
    "x_iters  = np.zeros((ensemble,n_tot,len(search_space))) # coordinates in hp space where f has been evaluated\n",
    "f_iters  = np.zeros((ensemble,n_tot))   # values of f at those coordinates\n",
    "minimum  = np.zeros((ensemble, len(search_space)+2))      # minima found per each member of the ensemble\n",
    "\n",
    "# to store optimal hyperparameters and matrices\n",
    "tikh_opt = np.zeros(n_tot)\n",
    "Woutt    = np.zeros(((ensemble, N_units+1,dim)))\n",
    "Winn     = [] #save as list to keep single elements sparse\n",
    "Ws       = [] \n",
    "biass    = []\n",
    "rho_ens  = []\n",
    "epsilon_ens = []\n",
    "sigma_in_ens = []\n",
    "Xa_cc        = []\n",
    "LHS_cc       = []\n",
    "RHS_cc       = []\n",
    "\n",
    "# save the final gp reconstruction for each network\n",
    "gps        = [None]*ensemble\n",
    "\n",
    "# to print performance of every set of hyperparameters\n",
    "# print_flag = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO fix k, global issues for classical hyperparam opt\n",
    "run_hyperparam = False\n",
    "\n",
    "if run_hyperparam:\n",
    "    for i in range(ensemble):\n",
    "        \n",
    "        print('Realization    :',i+1)\n",
    "        \n",
    "        k   = 0\n",
    "        \n",
    "        # Win and W generation\n",
    "        seed= i+1\n",
    "        rnd = np.random.RandomState(seed)\n",
    "\n",
    "        Win =  esn.gen_input_matrix(seed)\n",
    "        W =  esn.gen_reservoir_matrix(seed)\n",
    "        \n",
    "        # Bayesian Optimization\n",
    "        tt       = time.time()\n",
    "        res      = validate(val,kernell,search_space,n_in,n_tot,esn,tikh,N_fo,N_fw,N_in,N_val,N_washout,U,U_washout,U_tv,Y_tv,Win,W,tikh_opt)\n",
    "        print('Total time for the network:', time.time() - tt)\n",
    "        \n",
    "        #Saving Quantities for post_processing\n",
    "        gps[i]     = res.models[-1]    \n",
    "        gp         = gps[i]\n",
    "        x_iters[i] = np.array(res.x_iters)\n",
    "        f_iters[i] = np.array(res.func_vals)\n",
    "        minimum[i] = np.append(res.x,[tikh_opt[np.argmin(f_iters[i])],res.fun])\n",
    "        params     = gp.kernel_.get_params()\n",
    "        key        = sorted(params)\n",
    "        par[i]     = np.array([params[key[2]],params[key[5]][0], 1, gp.noise_,params[key[5]][1]])\n",
    "\n",
    "        esn.rho      = 10**minimum[i,0]\n",
    "        esn.epsilon  = minimum[i,1]\n",
    "        esn.sigma_in = minimum[i,2]\n",
    "\n",
    "        Woutt[i] = esn.train(U_washout, U_tv, Y_tv,Win,W)[1]\n",
    "\n",
    "        Winn    += [Win] \n",
    "        Ws      += [W]   \n",
    "\n",
    "        #Plotting Optimization Convergence for each network\n",
    "        print('Best Results: x', 10**minimum[i,0], minimum[i,1],minimum[i,2] ,minimum[i,3],', Min Obj Function =', minimum[i,4])\n",
    "        print('Hyperparamters:',esn.rho,esn.epsilon,esn.sigma_in)\n",
    "\n",
    "        plt.rcParams[\"figure.figsize\"] = (15,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realization    : 1\n",
      "Realization    : 2\n",
      "Realization    : 3\n",
      "Realization    : 4\n",
      "Realization    : 5\n"
     ]
    }
   ],
   "source": [
    "#hf       = h5py.File('./data/VPT_L96/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)) # L96 without noise , its the file for paper\n",
    "# hf       = h5py.File('./data/VPT_L96/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)+'-noise') # L96 with noise , paper results\n",
    "#hf       = h5py.File('./data/VPT_L96/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)+'-noise'+str(noise)+'new')\n",
    "\n",
    "#hf       = h5py.File('./data/VPT_L63/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-noise')\n",
    "# hf       = h5py.File('./data/VPT_L63/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-noise'+str(noise))\n",
    "hf       = h5py.File('./data/VPT_L63/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble))\n",
    "minimum       = np.array(hf.get('minimum'))\n",
    "hf.close()\n",
    "\n",
    "#hf       = h5py.File('./data/MFE/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)+'-noise') # With Noise\n",
    "# hf       = h5py.File('./data/MFE/minimum='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)) # Without noise\n",
    "# minimum       = np.array(hf.get('minimum'))\n",
    "# hf.close()\n",
    "\n",
    "\n",
    "for i in range(ensemble):\n",
    "    print('Realization    :',i+1)\n",
    "\n",
    "    esn.rho      = 10**minimum[i,0]\n",
    "    esn.epsilon  = minimum[i,1]\n",
    "    esn.sigma_in = minimum[i,2]\n",
    "    seed= i+1\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    \n",
    "    \n",
    "    Win =  esn.gen_input_matrix(seed)\n",
    "    W =  esn.gen_reservoir_matrix(seed)\n",
    "    \n",
    "    Xa, Wout_p, LHS, RHS =  esn.train(U_washout, U_tv, Y_tv,Win,W)\n",
    "    \n",
    "    Woutt[i] = Wout_p\n",
    "    \n",
    "    Winn    += [Win] \n",
    "    Ws      += [W]\n",
    "    Xa_cc   += [Xa]\n",
    "    LHS_cc  += [LHS]\n",
    "    RHS_cc  += [RHS]   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Reservoir Computing - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Qbit and Cbits\n",
    "n              = 9 # 9 Qubits and classical\n",
    "Nres           = 2**n # Total Reservoir Size\n",
    "qubits         = n\n",
    "\n",
    "# Required Input Parameters\n",
    "N_units_q      = Nres #neurons or N_res in paper\n",
    "bias_in        = np.array([np.mean(np.abs((U_data-u_mean)/norm))])  # Input bias, b_in to break the inherent symmetry of ESN Structure\n",
    "bias_out       = np.array([1]) #output bias \n",
    "\n",
    "# Hyperparameters\n",
    "tikh_q        = np.array([1e-12])  # Tikhonov Param (Beta),  adds a regularization or weight decay term that penalizes large Wout values \n",
    "sigma_in_q    = 1\n",
    "rho_q         = 1.0 # [Spectral Radius]\n",
    "epsilon_q     = 0.05 # Leaking Rate\n",
    "\n",
    "# Ensembles\n",
    "qu_ensemble   = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: config4 Emulator: qasm_sim Total shots: 1000 Individual Shots: 1000\n",
      "Network 1  out of  1\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "Configurations = ['Linear+Full+FullSymmetric','Linear+Linear+Linear','None+Linear+Linear','None+Full+FullSymmetric','None+Products+Linear']\n",
    "config_list    = ['config1','config2','config3','config4','config5']\n",
    "qc_type        = config_list[3]\n",
    "config         = 4 # for initializing class its +1 of the list above\n",
    "\n",
    "emulator_list  = ['sv_sim','qasm_sim']\n",
    "emulator       = emulator_list[1]\n",
    "\n",
    "method_list    = ['sv','shots1k','shots5k','shots10k','shots20k','shots30k','shots40k','shots50k','shots75k','shots100k','shots200k','shots1']\n",
    "shot_list      = [None,1000,5000,10000,20000,30000,40000,50000,75000,100000,200000,400000,1]\n",
    "\n",
    "## SHOT INPUT\n",
    "shot_index     = 1\n",
    "\n",
    "method = method_list[shot_index]\n",
    "total_shots  = shot_list[shot_index]\n",
    "\n",
    "\n",
    "shots = total_shots\n",
    "\n",
    "snapshots = 1\n",
    "print('Configuration:',qc_type,'Emulator:',emulator,'Total shots:',total_shots,'Individual Shots:',shots)\n",
    "\n",
    "# Initialize Class\n",
    "QESN   = QuantumReservoirNetwork(rho_q,epsilon_q,sigma_in_q,tikh_q,bias_in,bias_out,qubits,N_units_q,dim,config,emulator,shots,snapshots)\n",
    "\n",
    "# Parameterized or not\n",
    "QESN.method_qc(parameterized=False)\n",
    "\n",
    "# Generate parameterized quantum circuit for a given configuration\n",
    "# QESN.gen_param_quantumcircuit()\n",
    "\n",
    "quantum_training = True\n",
    "run_training     = True\n",
    "save_training    = False\n",
    "load_training    = False\n",
    "\n",
    "Xa_qq    = []\n",
    "Woutt_qq    = np.zeros(((qu_ensemble, QESN.N_units+1,dim)))\n",
    "LHS_qq   = []\n",
    "RHS_qq   = []\n",
    "alpha_qc = []\n",
    "\n",
    "eps_fix  = 0.05\n",
    "tikh_q   = np.array([1e-12])\n",
    "eps_q_list = np.linspace(0.05,0.3,qu_ensemble)\n",
    "eps_q_list = np.ones(len(eps_q_list))*eps_fix\n",
    "alpha_range    = 4*np.pi\n",
    "\n",
    "start = timer()\n",
    "\n",
    "if quantum_training:\n",
    "    for i in range(qu_ensemble):\n",
    "        \n",
    "        print('Network',i+1,' out of ',qu_ensemble)\n",
    "        seed           = i\n",
    "        \n",
    "        # Quantum Variational Part\n",
    "        QESN.epsilon_q = eps_q_list[i]\n",
    "\n",
    "        alpha_q          = QESN.gen_random_unitary(i,alpha_range)\n",
    "        alpha_qc        += [alpha_q]\n",
    "\n",
    "\n",
    "        if load_training:\n",
    "            print('Loading existing Wout matrix')\n",
    "            #hf       = h5py.File('./data/MFE/Woutt_qq='+str(dt)+'-Nres'+str(N_units_q)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'script')#+'-noise')\n",
    "            #hf        = h5py.File('./data/MFE/Woutt_qq='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(qu_ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'-scaling'+str(scaling)+'-noise'+str(noise)+'-'+str(method)+str(qc_type))\n",
    "            hf       = h5py.File('./data/VPT_L63/Woutt_qq='+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'-scaling'+str(scaling)+'-noise'+str(noise)+'-'+str(method)+str(qc_type))\n",
    "            #hf      = h5py.File('./data/{}_New/Woutt_qq='.format(save_fold)+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(qu_ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'-scaling'+str(scaling)+'-noise'+str(noise)+'-'+str(method)+str(qc_type))\n",
    "            #hf      = h5py.File('./data/{}/Woutt_qq='.format(save_fold)+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(qu_ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'-scaling'+str(scaling)+'-noise'+str(noise)+'-'+str(method)+str(qc_type))\n",
    "            \n",
    "            Woutt_qq       = np.array(hf.get('Woutt_qq'))\n",
    "            hf.close()\n",
    "        \n",
    "\n",
    "        if run_training:\n",
    "            print('Training...')\n",
    "            Xa_qc, Woutt_qc, LHS_qc, RHS_qc = QESN.quantum_training(U_washout, U_tv, Y_tv, alpha_qc[i])\n",
    "                    \n",
    "            Xa_qq       += [Xa_qc]\n",
    "            Woutt_qq[i]  = Woutt_qc # saving Output matrix as array \n",
    "            LHS_qq      += [LHS_qc]\n",
    "            RHS_qq      += [RHS_qc]\n",
    "                \n",
    "alpha_qq = alpha_qc\n",
    "# Woutt_qq = Woutt_qq\n",
    "\n",
    "if load_training:\n",
    "    Woutt_qq = np.reshape(Woutt_qq,[qu_ensemble, QESN.N_units+1,dim]) # If loading previously saved Woutt , need to reshape 4D to 2D\n",
    "\n",
    "end = timer()\n",
    "\n",
    "training_time = (end-start)\n",
    "print(training_time)\n",
    "\n",
    "\n",
    "if save_training:\n",
    "    fln      = ('./data/{}/Woutt_qq='.format(save_fold)+str(dt)+'-Nres'+str(N_units)+'-Ensemble'+str(qu_ensemble)+'-dim'+str(dim)+'-epsilon_q'+str(eps_fix)+'-tikh'+str(tikh_q)+'-scaling'+str(scaling)+'-noise'+str(noise)+'-'+str(method)+str(qc_type))\n",
    "    hf       = h5py.File(fln,'w')\n",
    "    hf.create_dataset('Woutt_qq',data=Woutt_qq)\n",
    "    hf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODIFY Post processing functionss\n",
    "quantum_plots = True\n",
    "N_test   = dim   #number of intervals in the test set\n",
    "N_tstart = N_washout          # where the first test interval starts\n",
    "N_intt   = 15*N_lyap          # length of each test set interval\n",
    "N_fwd    = 1*N_lyap\n",
    "\n",
    "len_open = N_washout          # Should be < N_washout because of implementation\n",
    "len_closed = 10*N_lyap\n",
    "\n",
    "factor = 100*N_lyap           # statistical predictions\n",
    "\n",
    "Y_tp      =  []\n",
    "Yh_tp     =  []\n",
    "Yh_t_qp   =  []\n",
    "PH_plot_p  =  []\n",
    "PH_plot_pq =  []\n",
    "PH_series  = []\n",
    "PH_series_q  = []\n",
    "\n",
    "time_series = np.array([0]) # relevant for MFE\n",
    "\n",
    "for j in range(len(time_series)):\n",
    "    num_series = time_series[j]\n",
    "    print('For time series',num_series)\n",
    "\n",
    "    for i in range(qu_ensemble):\n",
    "        seed  = i+1\n",
    "        Win   =  esn.gen_input_matrix(seed)\n",
    "        W     =  esn.gen_reservoir_matrix(seed)\n",
    "\n",
    "        if quantum_plots:\n",
    "            U_wash, Uh_wash , Y_t , Yh_t , PH_plot , Uh_wash_q, Yh_t_q , PH_plot_q = lorenz63_timeseries_plot(N_test,N_tstart,N_intt,N_fwd,j,UU,U,U_test,N_washout,N_lyap,ensemble,N_t,minimum,esn,Win,W,QESN,Woutt,Woutt_qq,alpha_qq,plot=True,quantum=True)\n",
    "            \n",
    "            Y_tp       +=  [Y_t]\n",
    "            Yh_tp      +=  [Yh_t]\n",
    "            Yh_t_qp    +=  [Yh_t_q]\n",
    "            PH_plot_p  += [PH_plot[i]]\n",
    "            PH_plot_pq += [PH_plot_q[i]]\n",
    "            \n",
    "        else:\n",
    "            U_wash, Uh_wash , Y_t , Yh_t , PH_plot , Uh_wash_q, Yh_t_q , PH_plot_q = lorenz63_timeseries_plot(N_test,N_tstart,N_intt,N_fwd,j,UU,U,U_test,N_washout,N_lyap,ensemble,N_t,minimum,esn,Win,W,QESN,Woutt,Woutt_qq,alpha_qq,plot=True,quantum=False)\n",
    "            Y_tp      +=  [Y_t]\n",
    "            Yh_tp     +=  [Yh_t]\n",
    "            PH_plot_p += [PH_plot[i]]\n",
    "            \n",
    "    PH_series   += [PH_plot_p]\n",
    "    PH_series_q += [PH_plot_pq]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_QRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
