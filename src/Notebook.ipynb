{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Dynamical Systems using Reservoir Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec(open(\"./QESN/solvers.py\").read())\n",
    "# exec(open(\"./QESN/systems.py\").read())\n",
    "# exec(open(\"./QESN/unitaryblock.py\").read())\n",
    "# exec(open(\"./QESN/post_process.py\").read())\n",
    "# exec(open(\"./QESN/esn_class.py\").read())\n",
    "# exec(open(\"./QRC/validation.py\").read())\n",
    "# exec(open(\"./QRC/crc.py\").read())\n",
    "# exec(open(\"./QESN/Qesn_class.py\").read())\n",
    "\n",
    "from QRC.solvers import *\n",
    "from QRC.systems import *\n",
    "from QRC.post_process import *\n",
    "from QRC.crc import *\n",
    "from QRC.validation import *\n",
    "\n",
    "import h5py\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "import sklearn , skopt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import eigs as sparse_eigs\n",
    "import skopt\n",
    "\n",
    "\n",
    "#plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex = True)\n",
    "mpl.rc('font', family = 'serif')\n",
    "mpl.rcParams['text.usetex']\n",
    "\n",
    "#scipy libraries\n",
    "from skopt.space import Real\n",
    "from skopt.learning import GaussianProcessRegressor as GPR\n",
    "from skopt.learning.gaussian_process.kernels import Matern, WhiteKernel, Product, ConstantKernel\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import math\n",
    "from skopt.plots import plot_convergence\n",
    "import scipy.stats as stats \n",
    "\n",
    "#QISKIT\n",
    "from qiskit import  QuantumCircuit, assemble, QuantumRegister, ClassicalRegister, transpile\n",
    "import random as rnd\n",
    "#from Unitary_Functions import *\n",
    "import time\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "# import sys\n",
    "# args = sys.argv\n",
    "#TODO\n",
    "# Add config file so that to run on HPC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Systems and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Lorenz 63:\n",
    "if __name__ == \"__main__\":\n",
    "    dt = 0.01\n",
    "    tot_steps = 100000\n",
    "    upsample = 1\n",
    "    q0 =  np.array([7.432487609628195, 10.02071718705213, 29.62297428638419])\n",
    "    #q0 =  np.array([0, 1, 1])\n",
    "    N_transient = 2000\n",
    "\n",
    "\n",
    "save_fold = 'VPT_L63'\n",
    "system = Systems(dt,tot_steps,q0,upsample,N_transient)\n",
    "\n",
    "dim,N_lyap,N_t = system.set_param_lorenz63() # FOR MFE, N_t should be input so in set_param_MFE -- make it as input\n",
    "q = system.gen_data_lorenz63()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laminarized precentage 0.0 (relevant for MFE)\n",
      "Retaining  1 series for training and validation\n",
      "Additional  500 series for testing and statistical predictions\n",
      "UU Size = (1, 98000, 3)\n",
      "U Size = (98000, 3)\n",
      "N_lyap: 111\n",
      "N_train = 20 N_lyap  x  1 series\n",
      "N = 27 N_lyap , Total steps of training= 2997 , Out of =  98000\n",
      "The shape of q_tv is (1, 98000, 3) to train on 1 time series\n",
      "The shape of q_test is (0, 98000, 3) to test 500 time series, and for stats predictions (relevant for MFE)\n",
      "The shape of q is (1, 98000, 3) combining above\n",
      "The shape of U_test is (1, 22199, 3) combining above\n"
     ]
    }
   ],
   "source": [
    "data_inputs = True\n",
    "noise       = False # to add noise in flattened time series \n",
    "scaling     = True # to scale flattened time series \n",
    "\n",
    "if data_inputs:\n",
    "    N_ts        = 1 #only first N_ts used for training and validation\n",
    "    N_test_stat = 500 # Time series for testing after N_ts\n",
    "\n",
    "    N_washout  = 2*N_lyap #10 before for L96 10 D , 2 before for L63 / MFE  \n",
    "    N_val      = 5*N_lyap # 3 for L63 , # 5 for L96 , 2*N_lyap for MFE\n",
    "    N_train    = 20*N_lyap #200 before for L96 10D , 20 before for L63 / MFE  \n",
    "    N_test     = 200*N_lyap\n",
    " \n",
    "\n",
    "\n",
    "# All above in this block are Inputs\n",
    "\n",
    "q_unscaled = q\n",
    "UU = q # backup of complete time series\n",
    "print('Laminarized precentage', np.round(100-((q.shape[0])*100/N_t),2),'(relevant for MFE)')\n",
    "\n",
    "q = q[:N_ts+N_test_stat,:,:] # trimmed time series\n",
    "\n",
    "print('Retaining ',N_ts, 'series for training and validation')\n",
    "print('Additional ',N_test_stat, 'series for testing and statistical predictions')\n",
    "\n",
    "\n",
    "# Rescaling Input Time Series after flattening it (only retained series)\n",
    "q0 = q.shape[0] # Total time series, Train+Val+Test\n",
    "q1 = q.shape[1] # Length of each time series\n",
    "q_U = q.reshape(q0*q1, dim)\n",
    "\n",
    "if scaling:\n",
    "    q = sklearn.preprocessing.minmax_scale(q_U, feature_range=(0, 1), axis=0, copy=True) # rescaling flattened array\n",
    "    q  = q.reshape(q0,q1,dim) # making 3 dimensional again\n",
    "\n",
    "# from here q has scaled data\n",
    "q_tv = q[:N_ts,:,:]  # From q retaining training set (N_ts)\n",
    "q_test = q[N_ts:N_ts+N_test_stat,:,:]  #From q removing retaining test set(N_test_stat)\n",
    "\n",
    "# Training, Validation Parameters\n",
    "UU = q_tv # Training, validation set\n",
    "N0 = UU.shape[0] # Retained Time series for training\n",
    "N1 = UU.shape[1] # Length of each time series\n",
    "print('UU Size =',UU.shape) # 3 dim\n",
    "U = UU.reshape(N0*N1, dim) # Generating flattened time series for addition of noise and normalization\n",
    "print('U Size =',U.shape) # 2 dim \n",
    "\n",
    "if noise: # adding noise in training set\n",
    "    target_snr_db=40\n",
    "    seed=0\n",
    "    UU = add_noise(U,target_snr_db,seed,dim,N0,N1)\n",
    "\n",
    "#compute norm\n",
    "U_data = U[:N_washout+N_train+N_val]\n",
    "m = U_data.min(axis=0)\n",
    "M = U_data.max(axis=0)\n",
    "norm = M-m\n",
    "u_mean = U_data.mean(axis=0)\n",
    "\n",
    "# washout\n",
    "U_washout = UU[:,:N_washout]\n",
    "# training\n",
    "U_t   = UU[:,N_washout:N_washout+N_train-1]\n",
    "Y_t   = UU[:,N_washout+1:N_washout+N_train]\n",
    "# validations\n",
    "Y_v  = UU[:,N_washout+N_train:N_washout+N_train+N_val]\n",
    "k_v  = 0.5*np.linalg.norm(Y_v[0], axis=1)**2\n",
    "# training + validation\n",
    "U_tv  = UU[:,N_washout:N_washout+N_train+N_val-1]\n",
    "Y_tv  = UU[:,N_washout+1:N_washout+N_train+N_val]\n",
    "# Testing\n",
    "U_test  = UU[:,N_washout+N_train+N_val:N_washout+N_train+N_val+N_test-1]\n",
    "Y_test  = UU[:,N_washout+N_train+N_val+1:N_washout+N_train+N_val+N_test]\n",
    "#Y_tv  = UU[:,N_washout+1:N_washout+N_train+N_val]\n",
    "\n",
    "print('N_lyap:', N_lyap)\n",
    "print('N_train =',int(N_train/N_lyap),'N_lyap',' x ',str(N_ts),'series')\n",
    "print('N =',int((N_washout+N_val+N_train)/N_lyap),'N_lyap',', Total steps of training=',int(N_washout+N_val+N_train),', Out of = ',N0*N1)\n",
    "print('The shape of q_tv is '+str(q_tv.shape)+ ' to train on ' +str(N_ts)+  ' time series')\n",
    "print('The shape of q_test is '+str(q_test.shape)+ ' to test ' +str(N_test_stat)+  ' time series, and for stats predictions (relevant for MFE)')\n",
    "print('The shape of q is '+str(q.shape)+ ' combining above')\n",
    "print('The shape of U_test is '+str(U_test.shape)+ ' combining above')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# l1 = 8000\n",
    "# l2= 5000\n",
    "# l3= 5000\n",
    "\n",
    "# plot_lorenz63_attractor(U,l1)\n",
    "# plot_lorenz63_time(U,N_lyap,l2,l3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reservoir Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density(D) =  0.11\n",
      "Connectivity =  56.21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Required Input Parameters\n",
    "bias_in   = np.array([np.mean(np.abs((U_data-u_mean)/norm))]) #input bias (average absolute value of the inputs)\n",
    "bias_out  = np.array([1.]) #output bias \n",
    "N_units   = 512 #neurons\n",
    "density = 0.11 # L63\n",
    "#density = 0.01 # L96\n",
    "#connectivity = 30\n",
    "\n",
    "# Predefining Hyperparameter to initiate a class\n",
    "tikh = np.array([1e-9])  # Tikhonov factor (optimize among the values in this list) #TODO\n",
    "sigma_in = 1 # input scaling\n",
    "rho = 1\n",
    "epsilon = 1\n",
    "\n",
    "# # Validation Length\n",
    "# N_tval = 3 \n",
    "\n",
    "# Random Weight Matrices Seed\n",
    "seed = 2\n",
    "\n",
    "sparseness = 1 - density\n",
    "connectivity = (1 -  sparseness)*(N_units-1)\n",
    "\n",
    "# sparseness = 1-((connectivity)/(N_units-1))\n",
    "# density    = 1-sparseness\n",
    "print('Density(D) = ',np.round(density,2))\n",
    "print('Connectivity = ', np.round(connectivity,2))\n",
    "\n",
    "esn = EchoStateNetwork(tikh,sigma_in,rho,epsilon,bias_in,bias_out,N_units,dim,density)\n",
    "esn.norm_u = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation (hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in        = 10               #Number of Initial random points\n",
    "n_tot       = 50               #Total number of function evaluations\n",
    "spec_in     = np.log10(0.01)   #range for hyperparameters \n",
    "spec_end    = np.log10(1.0)   \n",
    "epsilon_in  = 0.01\n",
    "epsilon_end = 1\n",
    "scaling_in  = 0.01\n",
    "scaling_end = 1\n",
    "#Number of Networks in the ensemble\n",
    "ensemble = 5      \n",
    "    \n",
    "search_space = [Real(spec_in, spec_end, name='spectral_radius'),\n",
    "            Real(epsilon_in, epsilon_end, name='epsilon'),\n",
    "            Real(scaling_in,scaling_end, name = 'input_scaling')]\n",
    "\n",
    "kernell = ConstantKernel(constant_value=1.0, constant_value_bounds=(1e-1, 3e0)) *\\\n",
    "            Matern(length_scale=[0.2,0.1,0.3], nu=2.5, length_scale_bounds=(5e-2, 1e1)) \n",
    "\n",
    "\n",
    "k= 0\n",
    "# Which validaton strategy (implemented in Val_Functions.ipynb)\n",
    "val      = RVC_Noise_upt\n",
    "N_fo     = max(50,2)            # number of validation intervals\n",
    "N_in     = N_washout                  # timesteps before the first validation interval (can't be 0 due to implementation)\n",
    "N_fw     = (N_train-N_val)//(N_fo-1) # how many steps forward the validation interval is shifted (in this way they are evenly spaced)\n",
    "\n",
    "#Quantities to be saved\n",
    "par      = np.zeros((ensemble, 5))      # GP parameters\n",
    "x_iters  = np.zeros((ensemble,n_tot,len(search_space))) # coordinates in hp space where f has been evaluated\n",
    "f_iters  = np.zeros((ensemble,n_tot))   # values of f at those coordinates\n",
    "minimum  = np.zeros((ensemble, len(search_space)+2))      # minima found per each member of the ensemble\n",
    "\n",
    "\n",
    "global tikh_opt, k, ti\n",
    "    \n",
    "# to store optimal hyperparameters and matrices\n",
    "tikh_opt = np.zeros(n_tot)\n",
    "Woutt    = np.zeros(((ensemble, N_units+1,dim)))\n",
    "Winn     = [] #save as list to keep single elements sparse\n",
    "Ws       = [] \n",
    "biass    = []\n",
    "rho_ens  = []\n",
    "epsilon_ens = []\n",
    "sigma_in_ens = []\n",
    "Xa_cc        = []\n",
    "LHS_cc       = []\n",
    "RHS_cc       = []\n",
    "\n",
    "# save the final gp reconstruction for each network\n",
    "gps        = [None]*ensemble\n",
    "\n",
    "# to print performance of every set of hyperparameters\n",
    "print_flag = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realization    : 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Bayesian Optimization\u001b[39;00m\n\u001b[1;32m     15\u001b[0m tt       \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 16\u001b[0m res      \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkernell\u001b[49m\u001b[43m,\u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_tot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mesn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtikh\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_fo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_fw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_washout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU_washout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU_tv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_tv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mWin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal time for the network:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tt)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Saving Quantities for post_processing\u001b[39;00m\n",
      "File \u001b[0;32m~/RF_QRC_repo/RF_QRC/src/QRC/validation.py:34\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(val, kernell, search_space, n_in, n_tot, esn, tikh, N_fo, N_fw, N_in, N_val, N_washout, U, U_washout, U_tv, Y_tv, Win, W)\u001b[0m\n\u001b[1;32m     31\u001b[0m val_func \u001b[38;5;241m=\u001b[39m  val_fun(val,esn,tikh,N_fo,N_fw,N_in,N_val,N_washout,U,U_washout,U_tv,Y_tv,Win,W)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#Bayesian Optimization #TODO\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mskopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# the function to minimize\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# the bounds on each dimension of x\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#base_estimator       = b_e,        # GP kernel\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43macq_func\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# the acquisition function\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_tot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# total number of evaluations of f\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m#x0                   = x1,        # Initial grid search points to be evaluated at\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# the number of initial random initialization points\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# number of tries for each acquisition\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# seed\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/RF_QRC_repo/venv_qrc/lib/python3.10/site-packages/skopt/optimizer/gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m, space\u001b[38;5;241m=\u001b[39mspace, random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    257\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RF_QRC_repo/venv_qrc/lib/python3.10/site-packages/skopt/optimizer/base.py:299\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[1;32m    298\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 299\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    301\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[0;32m~/RF_QRC_repo/RF_QRC/src/QRC/validation.py:81\u001b[0m, in \u001b[0;36mRVC_Noise_upt\u001b[0;34m(esn, tikh, N_fo, N_fw, N_in, N_val, N_washout, U, U_washout, U_tv, Y_tv, Win, W, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m         Yh_val   \u001b[38;5;241m=\u001b[39m esn\u001b[38;5;241m.\u001b[39mclosed_loop(N_val\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, xf, Wout[j],Win,W)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     79\u001b[0m         Mean[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mmean((Y_val\u001b[38;5;241m-\u001b[39mYh_val)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mk\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosed-loop time:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t1)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#select optimal tikh\u001b[39;00m\n\u001b[1;32m     84\u001b[0m a           \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(Mean)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(ensemble):\n",
    "    \n",
    "    print('Realization    :',i+1)\n",
    "    \n",
    "    k   = 0\n",
    "    \n",
    "    # Win and W generation\n",
    "    seed= i+1\n",
    "    rnd = np.random.RandomState(seed)\n",
    "\n",
    "    Win =  esn.gen_input_matrix(seed)\n",
    "    W =  esn.gen_reservoir_matrix(seed)\n",
    "    \n",
    "    # Bayesian Optimization\n",
    "    tt       = time.time()\n",
    "    res      = validate(val,kernell,search_space,n_in,n_tot,esn,tikh,N_fo,N_fw,N_in,N_val,N_washout,U,U_washout,U_tv,Y_tv,Win,W)\n",
    "    print('Total time for the network:', time.time() - tt)\n",
    "    \n",
    "    #Saving Quantities for post_processing\n",
    "    gps[i]     = res.models[-1]    \n",
    "    gp         = gps[i]\n",
    "    x_iters[i] = np.array(res.x_iters)\n",
    "    f_iters[i] = np.array(res.func_vals)\n",
    "    minimum[i] = np.append(res.x,[tikh_opt[np.argmin(f_iters[i])],res.fun])\n",
    "    params     = gp.kernel_.get_params()\n",
    "    key        = sorted(params)\n",
    "    par[i]     = np.array([params[key[2]],params[key[5]][0], 1, gp.noise_,params[key[5]][1]])\n",
    "\n",
    "    esn.rho      = 10**minimum[i,0]\n",
    "    esn.epsilon  = minimum[i,1]\n",
    "    esn.sigma_in = minimum[i,2]\n",
    "\n",
    "    Woutt[i] = esn.train(U_washout, U_tv, Y_tv,Win,W)[1]\n",
    "\n",
    "    Winn    += [Win] \n",
    "    Ws      += [W]   \n",
    "\n",
    "    #Plotting Optimization Convergence for each network\n",
    "    print('Best Results: x', 10**minimum[i,0], minimum[i,1],minimum[i,2] ,minimum[i,3],', Min Obj Function =', minimum[i,4])\n",
    "    print('Hyperparamters:',esn.rho,esn.epsilon,esn.sigma_in)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_QRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
